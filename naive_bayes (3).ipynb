{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t76_rmCYK70x",
        "outputId": "fc7586c1-f54f-4120-839a-06381e76f296"
      },
      "source": [
        "# link drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yby-WmxuLCuw",
        "outputId": "e5471c1b-1145-4ff4-d0b4-2e629c88b3ff"
      },
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "import pickle\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MmqQYkICLHXN",
        "outputId": "13600c6e-e5bf-4348-f2c2-f08b6b083791"
      },
      "source": [
        "# get training data \n",
        "train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/train.tsv', sep='\\t', header=0)\n",
        "train_pid = train_data['PhraseId'].tolist()\n",
        "train_sid = train_data['SentenceId'].tolist()\n",
        "train_phrase = train_data['Phrase'].tolist()\n",
        "train_y = train_data['Sentiment'].tolist()\n",
        "train_data\n",
        "\n",
        "# repeat this same process for the test data\n",
        "# recall that there is no sentiment column here\n",
        "test_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/test.tsv', sep='\\t', header=0)\n",
        "test_pid = test_data['PhraseId'].tolist()\n",
        "test_sid = test_data['SentenceId'].tolist()\n",
        "test_phrase = test_data['Phrase'].tolist()\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66287</th>\n",
              "      <td>222348</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66288</th>\n",
              "      <td>222349</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded , predictable scenario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66289</th>\n",
              "      <td>222350</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66290</th>\n",
              "      <td>222351</td>\n",
              "      <td>11855</td>\n",
              "      <td>A long-winded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66291</th>\n",
              "      <td>222352</td>\n",
              "      <td>11855</td>\n",
              "      <td>predictable scenario</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66292 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PhraseId  SentenceId                                             Phrase\n",
              "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2        156063        8545                                                 An\n",
              "3        156064        8545  intermittently pleasing but mostly routine effort\n",
              "4        156065        8545         intermittently pleasing but mostly routine\n",
              "...         ...         ...                                                ...\n",
              "66287    222348       11855             A long-winded , predictable scenario .\n",
              "66288    222349       11855               A long-winded , predictable scenario\n",
              "66289    222350       11855                                    A long-winded ,\n",
              "66290    222351       11855                                      A long-winded\n",
              "66291    222352       11855                               predictable scenario\n",
              "\n",
              "[66292 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4jY7BefLLL_",
        "outputId": "8d016b89-334e-400a-c3e2-5f058ca7e990"
      },
      "source": [
        "# create a function that preprocesses the words in each sentence\n",
        "# the goal of preprocessing is to be able to find all impactful words\n",
        "# as well as avoid treating similar words as separate\n",
        "# Ex: \"Cat\", \"CATS\", \"cats\", and \"cat\" should all be treated the same\n",
        "\n",
        "def phrase_preprocessor(phrases):\n",
        "  stemmer = WordNetLemmatizer()\n",
        "\n",
        "  processed_phrases = []\n",
        "\n",
        "  for sen in range(len(phrases)):\n",
        "    # remove special chars\n",
        "    phrase = re.sub(r'\\W', ' ', str(phrases[sen]))\n",
        "\n",
        "    # remove all single characters\n",
        "    phrase = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', phrase)\n",
        "\n",
        "    # removes single characters from start of phrase\n",
        "    phrase = re.sub(r'\\^[a-zA-Z]\\s+', ' ', phrase) \n",
        "\n",
        "    # replace multiple spaces with a single space\n",
        "    phrase = re.sub(r'\\s+', ' ', phrase, flags=re.I)\n",
        "\n",
        "    # make the phrase all lowercse\n",
        "    phrase = phrase.lower()\n",
        "\n",
        "    # lemmatization (i.e. remove small differences that dont't matter)\n",
        "    # Ex: \"cats\" -> \"cat\"\n",
        "    phrase = phrase.split()\n",
        "    phrase = [stemmer.lemmatize(word) for word in phrase]\n",
        "    phrase = ' '.join(phrase)\n",
        "\n",
        "    # append to output list\n",
        "    processed_phrases.append(phrase)\n",
        "\n",
        "  return processed_phrases\n",
        "\n",
        "# add a column of these processed phrases for both the train and test data\n",
        "test_processed = phrase_preprocessor(test_phrase)\n",
        "train_processed = phrase_preprocessor(train_phrase)\n",
        "\n",
        "# see the result on the first element of train_phrase\n",
        "print(train_processed[0])\n",
        "print(len(train_processed))\n",
        "\n",
        "# set up corpuses of data\n",
        "corpus= phrase_preprocessor(train_data['Phrase'])\n",
        "\n",
        "corpus1= phrase_preprocessor(test_data['Phrase'])\n",
        "\n",
        "print(len(corpus1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of story\n",
            "156060\n",
            "66292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8137sP0k_VC",
        "outputId": "304ae183-0b23-4ed3-9658-94665836f83d"
      },
      "source": [
        "# get counts of each sentiment\n",
        "\n",
        "word_count=pd.value_counts(train_data['Sentiment'].values, sort=False)\n",
        "word_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     7072\n",
              "1    27273\n",
              "2    79582\n",
              "3    32927\n",
              "4     9206\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWRKizlQbkb8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "x__train = cv.fit_transform(corpus).toarray()\n",
        "x__test= cv.fit_transform(corpus1).toarray()\n",
        "y = train_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y9nP--TenTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6ba4d9-e1be-4d61-80c8-21cad2390f7f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x__train, y, test_size = 0.40, random_state = 0)\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frHSj9ccio9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b06e00-73d1-45d4-f9d3-83293287d553"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_real_pred = classifier.predict(x__test)\n",
        "\n",
        "# compute accuracy\n",
        "\n",
        "count = 0\n",
        "preds = classifier.predict(X_test)\n",
        "for i in range(len(preds)):\n",
        "  if preds[i] == y_test[i]:\n",
        "    count += 1\n",
        "print(\"accuracy: \" + str(count/len(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.5851595540176855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k00Yfqz5SJOq",
        "outputId": "5439be51-8464-44c0-b55d-4afb582ae969"
      },
      "source": [
        "d = {'PhraseId':test_data['PhraseId'].tolist(), 'Sentiment':y_real_pred}\n",
        "df = pd.DataFrame(d)\n",
        "\n",
        "# create the csv and download it (in order to submit to Kaggle)\n",
        "from google.colab import files\n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/submission.csv', index=False)\n",
        "files.download('/content/drive/My Drive/Colab Notebooks/340W_Project/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8582a9b8-cb42-4f1d-902b-8e76689289c4\", \"submission.csv\", 596647)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}