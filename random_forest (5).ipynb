{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpUVqrkegBHg",
        "outputId": "7a05c23f-b4a9-41cb-8512-3dff01f33e20"
      },
      "source": [
        "# link drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq3GJaTsdkcs",
        "outputId": "4b38e2be-0b03-4fe7-df56-60c9afc19c0f"
      },
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "import pickle\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR1h4E83n9i1",
        "outputId": "b82aacc0-181d-4561-9378-91aff2c48106"
      },
      "source": [
        "# get training data \n",
        "train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/train.tsv', sep='\\t', header=0)\n",
        "train_pid = train_data['PhraseId'].tolist()\n",
        "train_sid = train_data['SentenceId'].tolist()\n",
        "train_phrase = train_data['Phrase'].tolist()\n",
        "train_y = train_data['Sentiment'].tolist()\n",
        "train_data\n",
        "\n",
        "# get only the rows of training data with the entire phrase\n",
        "\n",
        "sentence_dict = dict()\n",
        "for i in train_sid:\n",
        "  if i not in sentence_dict:\n",
        "    sentence_dict[i] = train_sid.index(i)\n",
        "\n",
        "new_train_sid = []\n",
        "new_train_pid = []\n",
        "new_train_phrase = []\n",
        "new_train_y = []\n",
        "\n",
        "for i in sentence_dict:\n",
        "  new_train_sid.append(train_sid[sentence_dict[i]])\n",
        "  new_train_pid.append(train_pid[sentence_dict[i]])\n",
        "  new_train_phrase.append(train_phrase[sentence_dict[i]])\n",
        "  new_train_y.append(train_y[sentence_dict[i]])\n",
        "\n",
        "train_sid = new_train_sid\n",
        "train_pid = new_train_pid\n",
        "train_phrase = new_train_phrase\n",
        "train_y = new_train_y\n",
        "\n",
        "print(train_pid[0], train_sid[0], train_phrase[0], train_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1 A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story . 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMfUPLL-rzfN",
        "outputId": "d9901f1f-e2b9-4001-f6cc-5001dfb4e80f"
      },
      "source": [
        "# repeat this same process for the test data\n",
        "# recall that there is no sentiment column here\n",
        "test_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/test.tsv', sep='\\t', header=0)\n",
        "test_pid = test_data['PhraseId'].tolist()\n",
        "test_sid = test_data['SentenceId'].tolist()\n",
        "test_phrase = test_data['Phrase'].tolist()\n",
        "test_data\n",
        "\n",
        "# get only the rows of training data with the entire phrase\n",
        "\n",
        "sentence_dict = dict()\n",
        "for i in test_sid:\n",
        "  if i not in sentence_dict:\n",
        "    sentence_dict[i] = test_sid.index(i)\n",
        "\n",
        "new_test_sid = []\n",
        "new_test_pid = []\n",
        "new_test_phrase = []\n",
        "new_test_y = []\n",
        "\n",
        "for i in sentence_dict:\n",
        "  new_test_sid.append(test_sid[sentence_dict[i]])\n",
        "  new_test_pid.append(test_pid[sentence_dict[i]])\n",
        "  new_test_phrase.append(test_phrase[sentence_dict[i]])\n",
        "\n",
        "test_sid = new_test_sid\n",
        "test_pid = new_test_pid\n",
        "test_phrase = new_test_phrase\n",
        "test_y = new_test_y\n",
        "\n",
        "print(test_pid[0], test_sid[0], test_phrase[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "156061 8545 An intermittently pleasing but mostly routine effort .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LebGbs511NZg",
        "outputId": "de6ce750-5f90-4a71-8cdc-d59e2c7c603b"
      },
      "source": [
        "# create a function that preprocesses the words in each sentence\n",
        "# the goal of preprocessing is to be able to find all impactful words\n",
        "# as well as avoid treating similar words as separate\n",
        "# Ex: \"Cat\", \"CATS\", \"cats\", and \"cat\" should all be treated the same\n",
        "\n",
        "def phrase_preprocessor(phrases):\n",
        "  stemmer = WordNetLemmatizer()\n",
        "\n",
        "  processed_phrases = []\n",
        "\n",
        "  for sen in range(len(phrases)):\n",
        "    # remove special chars\n",
        "    phrase = re.sub(r'\\W', ' ', str(phrases[sen]))\n",
        "\n",
        "    # remove all single characters\n",
        "    phrase = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', phrase)\n",
        "\n",
        "    # removes single characters from start of phrase\n",
        "    phrase = re.sub(r'\\^[a-zA-Z]\\s+', ' ', phrase) \n",
        "\n",
        "    # replace multiple spaces with a single space\n",
        "    phrase = re.sub(r'\\s+', ' ', phrase, flags=re.I)\n",
        "\n",
        "    # make the phrase all lowercse\n",
        "    phrase = phrase.lower()\n",
        "\n",
        "    # lemmatization (i.e. remove small differences that dont't matter)\n",
        "    # Ex: \"cats\" -> \"cat\"\n",
        "    phrase = phrase.split()\n",
        "    phrase = [stemmer.lemmatize(word) for word in phrase]\n",
        "    phrase = ' '.join(phrase)\n",
        "\n",
        "    # append to output list\n",
        "    processed_phrases.append(phrase)\n",
        "\n",
        "  return processed_phrases\n",
        "\n",
        "# add a column of these processed phrases for both the train and test data\n",
        "test_processed = phrase_preprocessor(test_phrase)\n",
        "train_processed = phrase_preprocessor(train_phrase)\n",
        "\n",
        "# see the result on the first element of train_phrase\n",
        "print(train_processed[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of story\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-NgVj2d4B-P",
        "outputId": "93815fa6-1978-4073-ae9c-e5705ac9578a"
      },
      "source": [
        "# convert the text to numbers that can be processed\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "####################\n",
        "# the hyperparameters in vectorizer WILL need to be tuned\n",
        "####################\n",
        "vectorizer = CountVectorizer(max_features=700, min_df=20, max_df=0.7, stop_words=stopwords.words('english'), analyzer='word')\n",
        "\n",
        "# train data being vectorized\n",
        "train_vectorized = vectorizer.fit_transform(train_processed).toarray()\n",
        "\n",
        "# test data being vectorized\n",
        "test_vectorized = vectorizer.fit_transform(test_processed).toarray()\n",
        "\n",
        "# view the results in train_vectorized[0]\n",
        "print(train_processed[0])\n",
        "print(train_vectorized[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of story\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcs19dcw8fjq",
        "outputId": "f876b8da-d685-4fab-8bc9-8577226676e4"
      },
      "source": [
        "# find term frequency and inverse document frequency\n",
        "# this is known as a tfidf score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidfconverter = TfidfTransformer()\n",
        "\n",
        "# train data\n",
        "train_tfidf = tfidfconverter.fit_transform(train_vectorized).toarray()\n",
        "\n",
        "# test data\n",
        "test_tfidf = tfidfconverter.fit_transform(test_vectorized).toarray()\n",
        "\n",
        "# view results in train_tfidf[0]\n",
        "print(train_tfidf[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.29859554 0.         0.         0.\n",
            " 0.         0.         0.38226082 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.49544891 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.25269274 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.37236332 0.         0.         0.\n",
            " 0.         0.37809071 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.34660074 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.23163554 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqyDL9X9-KUQ"
      },
      "source": [
        "# make a train / validation split on our training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnCqPwWC-zWq",
        "outputId": "0cfb4589-b7d2-4a13-994b-b2e97c843db7"
      },
      "source": [
        "# train a random forest classifier on the data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier # imported this to see if it was better. It was not.\n",
        "\n",
        "####################\n",
        "# check for results on ALL training rows\n",
        "train_pid = train_data['PhraseId'].tolist()\n",
        "train_sid = train_data['SentenceId'].tolist()\n",
        "train_phrase = train_data['Phrase'].tolist()\n",
        "train_y = train_data['Sentiment'].tolist()\n",
        "\n",
        "train_processed = phrase_preprocessor(train_phrase)\n",
        "\n",
        "train_vectorized = vectorizer.fit_transform(train_processed).toarray()\n",
        "\n",
        "train_tfidf = tfidfconverter.fit_transform(train_vectorized).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, test_size=0.2, random_state=0)\n",
        "\n",
        "####################\n",
        "# these hyperparameters WILL need to be tweaked\n",
        "####################\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=2, verbose=True)\n",
        "classifier.fit(X_train, y_train) \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# check the number of classes, should be five\n",
        "print(classifier.n_classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 136.4min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFB8zqRl_brM",
        "outputId": "fbaedb67-dc39-4b6e-c9f5-6c82c9d38dbd"
      },
      "source": [
        "# validate results\n",
        "# the bottommost number is our overall accuracy\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "####################\n",
        "# NOTE: We have not done anything with the test_... data from before. \n",
        "# this is because it has no sentiment column for us to compare to.\n",
        "# if we wish to submit our results to Kaggle, however, we need to use\n",
        "# our model to make prediction on test_tfidf\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  368   496   596    40     4]\n",
            " [  327  1674  3224   206    22]\n",
            " [   82   870 13870  1082    78]\n",
            " [   12   164  3348  2479   438]\n",
            " [    0    17   521   733   561]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.24      0.32      1504\n",
            "           1       0.52      0.31      0.39      5453\n",
            "           2       0.64      0.87      0.74     15982\n",
            "           3       0.55      0.38      0.45      6441\n",
            "           4       0.51      0.31      0.38      1832\n",
            "\n",
            "    accuracy                           0.61     31212\n",
            "   macro avg       0.54      0.42      0.46     31212\n",
            "weighted avg       0.59      0.61      0.58     31212\n",
            "\n",
            "0.60720235806741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STqx8UNmrfNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02f129fe-0ad6-4e08-b711-b84f767b0a4e"
      },
      "source": [
        "# create a csv to submit to Kaggle \n",
        "# for submission to Kaggle, we need to predict on all phrases, not just whole phrases\n",
        "# model accuracy may suffer as a result\n",
        "\n",
        "test_phrase2 = test_data['Phrase'].tolist()\n",
        "test_processed2 = phrase_preprocessor(test_phrase2)\n",
        "\n",
        "test_vectorized2 = vectorizer.fit_transform(test_processed2).toarray()\n",
        "\n",
        "test_tfidf2 = tfidfconverter.fit_transform(test_vectorized2).toarray()\n",
        "\n",
        "print(test_processed2[0])\n",
        "print(test_vectorized[0])\n",
        "print(test_tfidf2[0])\n",
        "\n",
        "y_pred2 = classifier.predict(test_tfidf2)\n",
        "\n",
        "d = {'PhraseId':test_data['PhraseId'].tolist(), 'Sentiment':y_pred2}\n",
        "df = pd.DataFrame(d)\n",
        "\n",
        "# create the csv and download it (in order to submit to Kaggle)\n",
        "from google.colab import files\n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/340W_Project/data/submission.csv', index=False)\n",
        "files.download('/content/drive/My Drive/Colab Notebooks/340W_Project/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an intermittently pleasing but mostly routine effort\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.68621154 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.72740204 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_00b52555-ce6c-4775-b3ea-d73b6086afa4\", \"submission.csv\", 596647)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cproh33wys5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d12c231-92c4-4b0d-eb35-2401493dd3fc"
      },
      "source": [
        "# examine phrases, their predictions, and true values for the first few rows of data to see what might cause failures\n",
        "for i in range(20):\n",
        "  print(train_phrase[i], y_pred[i], y_train[i])\n",
        "  print(\" \")\n",
        "\n",
        "####################\n",
        "# Our model still seems to struggle with sentence negation and indirect language.\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story . 2 2\n",
            " \n",
            "A series of escapades demonstrating the adage that what is good for the goose 2 1\n",
            " \n",
            "A series 2 3\n",
            " \n",
            "A 1 4\n",
            " \n",
            "series 3 4\n",
            " \n",
            "of escapades demonstrating the adage that what is good for the goose 2 2\n",
            " \n",
            "of 2 3\n",
            " \n",
            "escapades demonstrating the adage that what is good for the goose 2 2\n",
            " \n",
            "escapades 2 3\n",
            " \n",
            "demonstrating the adage that what is good for the goose 2 2\n",
            " \n",
            "demonstrating the adage 3 2\n",
            " \n",
            "demonstrating 2 2\n",
            " \n",
            "the adage 2 0\n",
            " \n",
            "the 2 2\n",
            " \n",
            "adage 2 3\n",
            " \n",
            "that what is good for the goose 2 3\n",
            " \n",
            "that 2 2\n",
            " \n",
            "what is good for the goose 2 2\n",
            " \n",
            "what 2 2\n",
            " \n",
            "is good for the goose 2 2\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9xXQysvzGsQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1661b88e-5f50-4599-c705-e1d250e69b9c"
      },
      "source": [
        "# view data\n",
        "\n",
        "train_data[0:60]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>the adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>the</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>that</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>what</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>is</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>good for the goose</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>for</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>is also good for the gander , some of which oc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>is also good for the gander , some of which oc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>is also</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>also</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>good for the gander , some of which occasional...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>for the gander , some of which occasionally am...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>the gander , some of which occasionally amuses...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>the gander ,</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>the gander</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>gander</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>,</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>some of which occasionally amuses but none of ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>some of which</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>some</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>of which</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>which</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>occasionally amuses but none of which amounts ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>occasionally</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>amuses but none of which amounts to much of a ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>amuses</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>but none of which amounts to much of a story</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>but</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>none of which amounts to much of a story</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>none</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>of which amounts to much of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>which amounts to much of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>amounts to much of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>amounts</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>to much of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>to</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>much of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>much</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>of a story</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PhraseId  ...  Sentiment\n",
              "0          1  ...          1\n",
              "1          2  ...          2\n",
              "2          3  ...          2\n",
              "3          4  ...          2\n",
              "4          5  ...          2\n",
              "5          6  ...          2\n",
              "6          7  ...          2\n",
              "7          8  ...          2\n",
              "8          9  ...          2\n",
              "9         10  ...          2\n",
              "10        11  ...          2\n",
              "11        12  ...          2\n",
              "12        13  ...          2\n",
              "13        14  ...          2\n",
              "14        15  ...          2\n",
              "15        16  ...          2\n",
              "16        17  ...          2\n",
              "17        18  ...          2\n",
              "18        19  ...          2\n",
              "19        20  ...          2\n",
              "20        21  ...          2\n",
              "21        22  ...          3\n",
              "22        23  ...          3\n",
              "23        24  ...          2\n",
              "24        25  ...          2\n",
              "25        26  ...          2\n",
              "26        27  ...          2\n",
              "27        28  ...          2\n",
              "28        29  ...          2\n",
              "29        30  ...          2\n",
              "30        31  ...          2\n",
              "31        32  ...          2\n",
              "32        33  ...          2\n",
              "33        34  ...          1\n",
              "34        35  ...          2\n",
              "35        36  ...          2\n",
              "36        37  ...          2\n",
              "37        38  ...          2\n",
              "38        39  ...          2\n",
              "39        40  ...          2\n",
              "40        41  ...          2\n",
              "41        42  ...          2\n",
              "42        43  ...          2\n",
              "43        44  ...          2\n",
              "44        45  ...          2\n",
              "45        46  ...          2\n",
              "46        47  ...          3\n",
              "47        48  ...          1\n",
              "48        49  ...          2\n",
              "49        50  ...          1\n",
              "50        51  ...          2\n",
              "51        52  ...          2\n",
              "52        53  ...          2\n",
              "53        54  ...          2\n",
              "54        55  ...          2\n",
              "55        56  ...          2\n",
              "56        57  ...          2\n",
              "57        58  ...          2\n",
              "58        59  ...          2\n",
              "59        60  ...          2\n",
              "\n",
              "[60 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}